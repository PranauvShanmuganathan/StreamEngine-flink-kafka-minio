# Real-Time Data Lakehouse Platform

This project sets up a real-time data lakehouse platform using a suite of powerful open-source tools. All components are containerized using Docker for easy deployment and scalability.

## ðŸš€ Getting Started

Follow these instructions to get the entire platform up and running on your local machine.

### **Prerequisites**

* [Docker](https://docs.docker.com/get-docker/)
* [Docker Compose](https://docs.docker.com/compose/install/)

---

### **Installation**

1.  **Clone the repository**
    ```bash
    git clone <your-repository-url>
    cd <your-repository-name>
    ```

2.  **Start All Services**
    Run the following command in your terminal to build and start all the services in detached mode.
    ```bash
    docker-compose up -d
    ```

    > **Note:** All components (Kafka, Flink, Iceberg, Trino, MinIO, and Superset) are containerized using Docker for easy deployment and scalability.

---

### **Accessing Services**

Once the containers are up and running, you can access the various services through your web browser using the following URLs and credentials:

| Service               | URL                           | Credentials          |
| --------------------- | ----------------------------- | -------------------- |
| Kafka Control Center  | `http://localhost:9021`       | No Auth              |
| Flink Dashboard       | `http://localhost:18081`      | No Auth              |
| MinIO Console         | `http://localhost:9001`       | `admin` / `password` |
| Trino UI              | `http://localhost:8080/ui`    | No Auth              |
| Superset              | `http://localhost:8088`       | `admin` / `admin`    |
